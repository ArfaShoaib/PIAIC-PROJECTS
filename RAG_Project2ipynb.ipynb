{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOXxRmQqYjYVVeFUEMGJTsk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArfaShoaib/PIAIC-PROJECTS/blob/main/RAG_Project2ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "WH6alxpFZvpa"
      },
      "outputs": [],
      "source": [
        "%pip install -qU langchain-pinecone langchain-google-genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import userdata\n",
        "userdata.get('PINECONE_API_KEY')\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "\n",
        "\n",
        "\n",
        "pinecone_api_key = userdata.get('PINECONE_API_KEY')\n",
        "\n",
        "pc = Pinecone(api_key=pinecone_api_key)"
      ],
      "metadata": {
        "id": "angDJAPU11C_"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "index_name = \"rag-project\"  # change if desired\n",
        "\n",
        "# Connect to the existing index if it exists, otherwise create it\n",
        "try:\n",
        "    index = pc.Index(index_name)  # Attempt to connect to the existing index\n",
        "    print(f\"Connected to existing index: {index_name}\")\n",
        "except:\n",
        "    pc.create_index(  # Create a new index if it doesn't exist\n",
        "            name=index_name,\n",
        "            dimension=768,\n",
        "            metric=\"cosine\",\n",
        "            spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
        "     )\n",
        "    index = pc.Index(index_name)\n",
        "    print(f\"Created new index: {index_name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ohmirndg2cKX",
        "outputId": "2839f6b7-848d-417c-d6ae-2df18b5b8ad2"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connected to existing index: rag-project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n"
      ],
      "metadata": {
        "id": "Rl80wJ7x81aE"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector = embeddings.embed_query(\"hello, world!\")\n",
        "vector[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMEhbUyu_FKk",
        "outputId": "af503fa3-4e05-4b17-b9b6-1f8a6b865578"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.05168594419956207,\n",
              " -0.030764883384108543,\n",
              " -0.03062233328819275,\n",
              " -0.02802734263241291,\n",
              " 0.01813093200325966]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_pinecone import PineconeVectorStore\n",
        "\n",
        "vector_store = PineconeVectorStore(index=index, embedding=embeddings)"
      ],
      "metadata": {
        "id": "duBm4Ut3_lJt"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Data Save\n",
        "from uuid import uuid4\n",
        "\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "document_1 = Document(\n",
        "    page_content=\"I had chocalate chip pancakes and scrambled eggs for breakfast this morning.\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "\n",
        "document_2 = Document(\n",
        "    page_content=\"The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\",\n",
        "    metadata={\"source\": \"news\"},\n",
        ")\n",
        "\n",
        "document_3 = Document(\n",
        "    page_content=\"Building an exciting new project with LangChain - come check it out!\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "\n",
        "document_4 = Document(\n",
        "    page_content=\"Robbers broke into the city bank and stole $1 million in cash.\",\n",
        "    metadata={\"source\": \"news\"},\n",
        ")\n",
        "\n",
        "document_5 = Document(\n",
        "    page_content=\"Wow! That was an amazing movie. I can't wait to see it again.\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "\n",
        "document_6 = Document(\n",
        "    page_content=\"Is the new iPhone worth the price? Read this review to find out.\",\n",
        "    metadata={\"source\": \"website\"},\n",
        ")\n",
        "\n",
        "document_7 = Document(\n",
        "    page_content=\"The top 10 soccer players in the world right now.\",\n",
        "    metadata={\"source\": \"website\"},\n",
        ")\n",
        "\n",
        "document_8 = Document(\n",
        "    page_content=\"LangGraph is the best framework for building stateful, agentic applications!\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "\n",
        "document_9 = Document(\n",
        "    page_content=\"The stock market is down 500 points today due to fears of a recession.\",\n",
        "    metadata={\"source\": \"news\"},\n",
        ")\n",
        "\n",
        "document_10 = Document(\n",
        "    page_content=\"I have a bad feeling I am going to get deleted :(\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "\n",
        "documents = [\n",
        "    document_1,\n",
        "    document_2,\n",
        "    document_3,\n",
        "    document_4,\n",
        "    document_5,\n",
        "    document_6,\n",
        "    document_7,\n",
        "    document_8,\n",
        "    document_9,\n",
        "    document_10,\n",
        "]\n"
      ],
      "metadata": {
        "id": "Pkrdb1hy_uxG"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uuids = [str(uuid4()) for _ in range(len(documents))]\n",
        "\n",
        "vector_store.add_documents(documents=documents, ids=uuids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEoO2cr_ASbA",
        "outputId": "a5099d21-ea90-491c-9371-407ad57fd32a"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['e91180af-3c5d-4234-a158-21c34c05dc13',\n",
              " '0e6c16bc-3d16-4722-a837-44499e799b70',\n",
              " '2326c101-4ce3-4568-9315-c66f6f43916b',\n",
              " 'be6f48d1-5285-4225-8f8e-e7647c5b627e',\n",
              " 'db878ffe-6a19-438e-9305-58b5ded8b145',\n",
              " '47420564-3eb3-49c7-a078-e9c612969260',\n",
              " 'b65b520a-2965-4f2b-a94c-05fe3c6a124c',\n",
              " '01aaada1-f54d-4ebb-81df-5bc9693d528f',\n",
              " 'a46be66c-0490-4b4a-a189-1d7cecc738c2',\n",
              " '9f47f7e5-d344-496e-8485-a79aa9401f69']"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Data Reterive\n",
        "results = vector_store.similarity_search(\n",
        "    \"LangChain provides abstractions to make working with LLMs easy\",\n",
        "    k=2,\n",
        "    filter={\"source\": \"tweet\"},\n",
        ")\n",
        "for res in results:\n",
        "    print(f\"* {res.page_content} [{res.metadata}]\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbxCXcX3BOzg",
        "outputId": "52215824-0109-4e6c-f86d-4f651a7ed671"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* LangGraph is the best framework for building stateful, agentic applications! [{'source': 'tweet'}]\n",
            "* Building an exciting new project with LangChain - come check it out! [{'source': 'tweet'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = vector_store.similarity_search_with_score(\n",
        "    \"Will it be hot tomorrow?\", k=1, filter={\"source\": \"news\"}\n",
        ")\n",
        "for res, score in results:\n",
        "    print(f\"* [SIM={score:3f}] {res.page_content} [{res.metadata}]\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-v6sPk5xBXOE",
        "outputId": "d1006741-efb4-4e78-8160-f9180b5db734"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* [SIM=0.668031] The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees. [{'source': 'news'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",\n",
        "    temperature=0,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        "    # other params...\n",
        ")"
      ],
      "metadata": {
        "id": "f9v8V6dgJ8_1"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def answers(query:str):\n",
        "  #Vector Search\n",
        "  vector_results = vector_store.similarity_search(query , k=2)\n",
        "  print(len(vector_results))\n",
        "\n",
        "  #PassnTo Model Vector Result + User Query\n",
        "  final_answer =llm.invoke(f\"answer this user query: {query}, here are some refrences {vector_results}\")\n",
        "\n",
        "\n",
        "  return final_answer"
      ],
      "metadata": {
        "id": "VRDnOiefB0Pd"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answers(\"LangChain provides abstractions to make working with LLMs easy\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMipi0fFLFWY",
        "outputId": "5082b1fa-4a4b-405f-c4c3-b8f7dd1769c1"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"The provided text mentions LangChain's ease of use with LLMs (Large Language Models), but the references are actually about LangGraph, a different framework for building stateful, agentic applications.  The references don't support the claim about LangChain.  Therefore, the query cannot be answered using the provided information.  To answer the query about LangChain's ease of use, different references focusing on LangChain would be needed.\\n\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-97b0b78e-36d9-4211-930e-cbd3e7b18d91-0', usage_metadata={'input_tokens': 149, 'output_tokens': 91, 'total_tokens': 240, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    }
  ]
}